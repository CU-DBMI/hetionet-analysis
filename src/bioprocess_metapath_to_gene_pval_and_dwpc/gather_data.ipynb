{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc183d5-7a0d-4a1a-b0b5-c87a5f54214b",
   "metadata": {},
   "source": [
    "# Biological Process and Gene Metapath Data Gathering\n",
    "\n",
    "- Each value from `BP.csv` is a source and each value from `Gene.csv` is a target. \n",
    "- Each source + target pairing may have a metapath which is found within `metapaths.csv`.\n",
    "- For each pair metapath we need the DWPC and p-value stored in a table for reference.\n",
    "- Ignore metapaths found within `metapaths_ignore.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb23bdc3-241a-47e0-8016-0533730762b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from itertools import product\n",
    "from typing import Generator, Iterator, Tuple\n",
    "\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "\n",
    "import hetionet_utils.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcfec16f-7ca2-46a0-af99-149753bed7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results folder\n",
    "pathlib.Path(\"data/results\").mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize your LanceDB database and table\n",
    "db = lancedb.connect(\"data/results/bioprocess_and_gene_metapaths\")\n",
    "table_name = \"bioprocess_gene_metapath_combinations\"\n",
    "\n",
    "# If the table does not exist, create it with an initial empty DataFrame\n",
    "if table_name not in db.table_names():\n",
    "    db.create_table(\n",
    "        table_name, pd.DataFrame(columns=[\"source_id\", \"target_id\", \"metapath\"])\n",
    "    )\n",
    "\n",
    "table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33492577-2f44-404f-b866-f76a54de28ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arrow_table(file_path: str, column_name: str) -> pa.Table:\n",
    "    \"\"\"Loads a single-column Arrow Table from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        column_name (str): The name of the column to extract.\n",
    "\n",
    "    Returns:\n",
    "        pa.Table: Arrow Table with the specified column.\n",
    "    \"\"\"\n",
    "    table = csv.read_csv(file_path)\n",
    "    return table.select([column_name])\n",
    "\n",
    "\n",
    "def generate_combinations(\n",
    "    table_bioprocesses: pa.Table, table_genes: pa.Table, table_metapaths: pa.Table\n",
    ") -> Generator[Tuple[str, str, str], None, None]:\n",
    "    \"\"\"Generates all possible combinations of IDs from three Arrow tables.\n",
    "\n",
    "    Args:\n",
    "        table_bioprocesses (pa.Table): Arrow Table containing bioprocess IDs in an 'id' column.\n",
    "        table_genes (pa.Table): Arrow Table containing gene IDs in an 'id' column.\n",
    "        table_metapaths (pa.Table): Arrow Table containing metapath values in a 'metapath' column.\n",
    "\n",
    "    Yields:\n",
    "        Tuple[str, str, str]: A tuple with a bioprocess ID, a gene ID, and a metapath value.\n",
    "    \"\"\"\n",
    "    for combo in product(\n",
    "        table_bioprocesses[\"id\"].to_pylist(),\n",
    "        table_genes[\"id\"].to_pylist(),\n",
    "        table_metapaths[\"metapath\"].to_pylist(),\n",
    "    ):\n",
    "        yield combo\n",
    "\n",
    "\n",
    "def process_in_chunks(\n",
    "    generator: Iterator[Tuple[str, str, str]], chunk_size: int = 1000\n",
    ") -> Iterator[pa.Table]:\n",
    "    \"\"\"Processes combinations from a generator in smaller chunks as Arrow Tables.\n",
    "\n",
    "    Args:\n",
    "        generator (Iterator[Tuple[str, str, str]]): A generator that yields tuples of combinations.\n",
    "        chunk_size (int, optional): The number of rows per chunk. Defaults to 1000.\n",
    "\n",
    "    Yields:\n",
    "        pa.Table: An Arrow Table containing a chunk of combinations with columns ['source_id', 'target_id', 'metapath'].\n",
    "    \"\"\"\n",
    "    chunk = []\n",
    "    for i, combo in enumerate(generator):\n",
    "        # Convert each combination to a tuple of strings to avoid None values\n",
    "        combo = tuple(str(x) if x is not None else \"\" for x in combo)\n",
    "        chunk.append(combo)\n",
    "\n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            # Create Arrow Table from the chunk\n",
    "            yield pa.table(\n",
    "                {\n",
    "                    \"source_id\": [row[0] for row in chunk],\n",
    "                    \"target_id\": [row[1] for row in chunk],\n",
    "                    \"metapath\": [row[2] for row in chunk],\n",
    "                }\n",
    "            )\n",
    "            chunk = []\n",
    "\n",
    "    # Yield any remaining combinations as an Arrow Table\n",
    "    if chunk:\n",
    "        yield pa.table(\n",
    "            {\n",
    "                \"source_id\": [row[0] for row in chunk],\n",
    "                \"target_id\": [row[1] for row in chunk],\n",
    "                \"metapath\": [row[2] for row in chunk],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22142383-8ae8-4c3a-b5ac-17c9f2dfc409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metapath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPpGdAdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPpGdAeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPpGdAuG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPpGeAdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPpGeAeG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metapath\n",
       "5  BPpGdAdG\n",
       "6  BPpGdAeG\n",
       "7  BPpGdAuG\n",
       "8  BPpGeAdG\n",
       "9  BPpGeAeG"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather metapaths which are not in the metapaths_ignore.csv\n",
    "df_metapaths = pd.read_csv(\"data/sources/metapaths.csv\")\n",
    "df_metapaths_ignore = pd.read_csv(\"data/sources/metapaths_ignore.csv\")\n",
    "df_metapaths = df_metapaths[\n",
    "    ~df_metapaths[\"metapath\"].isin(df_metapaths_ignore[\"metapath\"])\n",
    "]\n",
    "df_metapaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e228fb04-ba5c-4e44-b5bd-aa1f7816ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bioprocesses:\n",
      "            id                                 name\n",
      "0  GO:0000002     mitochondrial genome maintenance\n",
      "1  GO:0000012           single strand break repair\n",
      "2  GO:0000018      regulation of DNA recombination\n",
      "3  GO:0000019  regulation of mitotic recombination\n",
      "4  GO:0000022           mitotic spindle elongation \n",
      "\n",
      " genes:\n",
      "       id  name\n",
      "0      1  A1BG\n",
      "1     10  NAT2\n",
      "2    100   ADA\n",
      "3   1000  CDH2\n",
      "4  10000  AKT3\n"
     ]
    }
   ],
   "source": [
    "# read the biological processes and genes\n",
    "df_bioprocesses = pd.read_csv(\"data/sources/BP.csv\")\n",
    "df_genes = pd.read_csv(\"data/sources/Gene.csv\")\n",
    "\n",
    "print(\"bioprocesses:\\n\", df_bioprocesses.head(), \"\\n\\n\", \"genes:\\n\", df_genes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b75acd4-2bb3-4adf-a851-d758e75b22b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding chunk 1\n",
      "<class 'pyarrow.lib.Table'>\n",
      "source_id: string\n",
      "target_id: string\n",
      "metapath: string\n"
     ]
    },
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported cast from string to null using function cast_null",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(chunk_table))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunk_table\u001b[38;5;241m.\u001b[39mschema)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/lancedb/table.py:1509\u001b[0m, in \u001b[0;36mLanceTable.add\u001b[0;34m(self, data, mode, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add data to the table.\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03mIf vector columns are missing and the table\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;124;03mhas embedding functions, then the vector columns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124;03m    The number of vectors in the table.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;66;03m# TODO: manage table listing and metadata separately\u001b[39;00m\n\u001b[0;32m-> 1509\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# Access the dataset_mut property to ensure that the dataset is mutable.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref\u001b[38;5;241m.\u001b[39mdataset_mut\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/lancedb/table.py:154\u001b[0m, in \u001b[0;36m_sanitize_data\u001b[0;34m(data, schema, metadata, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m    151\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(metadata)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# TODO improve the logics in _sanitize_schema\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     schema \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mschema\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/lancedb/table.py:2033\u001b[0m, in \u001b[0;36m_sanitize_schema\u001b[0;34m(data, schema, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   2025\u001b[0m             likely_vector_col \u001b[38;5;129;01mor\u001b[39;00m is_default_vector_col\n\u001b[1;32m   2026\u001b[0m         ):\n\u001b[1;32m   2027\u001b[0m             data \u001b[38;5;241m=\u001b[39m _sanitize_vector_column(\n\u001b[1;32m   2028\u001b[0m                 data,\n\u001b[1;32m   2029\u001b[0m                 vector_column_name\u001b[38;5;241m=\u001b[39mfield\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   2030\u001b[0m                 on_bad_vectors\u001b[38;5;241m=\u001b[39mon_bad_vectors,\n\u001b[1;32m   2031\u001b[0m                 fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   2032\u001b[0m             )\n\u001b[0;32m-> 2033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[38;5;66;03m# just check the vector column\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m VECTOR_COLUMN_NAME \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumn_names:\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/table.pxi:4851\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/table.pxi:1608\u001b[0m, in \u001b[0;36mpyarrow.lib._sanitize_arrays\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:397\u001b[0m, in \u001b[0;36mpyarrow.lib.asarray\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/table.pxi:593\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray.cast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/compute.py:405\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(arr, target_type, safe, options, memory_pool)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         options \u001b[38;5;241m=\u001b[39m CastOptions\u001b[38;5;241m.\u001b[39msafe(target_type)\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43marr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_pool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/_compute.pyx:598\u001b[0m, in \u001b[0;36mpyarrow._compute.call_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/_compute.pyx:393\u001b[0m, in \u001b[0;36mpyarrow._compute.Function.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/work/hetionet-analysis/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported cast from string to null using function cast_null"
     ]
    }
   ],
   "source": [
    "# Load input CSV files into Arrow Tables\n",
    "table_bioprocesses = load_arrow_table(\"data/sources/BP.csv\", \"id\")\n",
    "table_genes = load_arrow_table(\"data/sources/Gene.csv\", \"id\")\n",
    "table_metapaths = pa.Table.from_pandas(df_metapaths)\n",
    "\n",
    "# Generate combinations\n",
    "generator = generate_combinations(table_bioprocesses, table_genes, table_metapaths)\n",
    "\n",
    "count = 1\n",
    "# Process and print chunks\n",
    "for chunk_table in process_in_chunks(generator):\n",
    "    # add the chunk to the table\n",
    "    print(f\"Adding chunk {count}\")\n",
    "    print(type(chunk_table))\n",
    "    print(chunk_table.schema)\n",
    "    table.add(chunk_table)\n",
    "    count += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3f235a7-e777-4252-82fc-a71c1c284abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>metapath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>BPpGdAdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>BPpGdAeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>BPpGdAuG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>BPpGeAdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>BPpGeAeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>100</td>\n",
       "      <td>BPpGdAeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>100</td>\n",
       "      <td>BPpGdAuG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>100</td>\n",
       "      <td>BPpGeAdG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>100</td>\n",
       "      <td>BPpGeAeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>100</td>\n",
       "      <td>BPpGeAuG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source_id target_id  metapath\n",
       "0   GO:0000002         1  BPpGdAdG\n",
       "1   GO:0000002         1  BPpGdAeG\n",
       "2   GO:0000002         1  BPpGdAuG\n",
       "3   GO:0000002         1  BPpGeAdG\n",
       "4   GO:0000002         1  BPpGeAeG\n",
       "..         ...       ...       ...\n",
       "95  GO:0000002       100  BPpGdAeG\n",
       "96  GO:0000002       100  BPpGdAuG\n",
       "97  GO:0000002       100  BPpGeAdG\n",
       "98  GO:0000002       100  BPpGeAeG\n",
       "99  GO:0000002       100  BPpGeAuG\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a04d5361-6ef1-48c1-8a58-50986d8f63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.to_csv(\"testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828431ff-398c-4c23-9fa7-f65a3925597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inserting all chunks, show the shape of the table\n",
    "num_rows = table.count()\n",
    "num_columns = len(table.schema().names)\n",
    "\n",
    "print(f\"Table shape: ({num_rows}, {num_columns})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
